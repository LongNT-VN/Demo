{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Khoi tao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .appName('movieRecommendationPySpark') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setCheckpointDir('checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Load du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (\n",
    "    spark.read.csv(\n",
    "        path = \"../data/ml-25m/ratings.csv\",\n",
    "        sep=\",\", header=True,quote='\"',schema=\"userId INT, movieId INT, rating DOUBLE, timestamp INT\",\n",
    "    ).select(\"userId\", \"movieId\", \"rating\")\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|1     |296    |5.0   |\n",
      "|1     |306    |3.5   |\n",
      "|1     |307    |5.0   |\n",
      "|1     |665    |5.0   |\n",
      "|1     |899    |3.5   |\n",
      "|1     |1088   |4.0   |\n",
      "|1     |1175   |3.5   |\n",
      "|1     |1217   |3.5   |\n",
      "|1     |1237   |5.0   |\n",
      "|1     |1250   |4.0   |\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|           userId|           movieId|            rating|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|         25000095|          25000095|          25000095|\n",
      "|   mean|81189.28115381162|21387.981943268616| 3.533854451353085|\n",
      "| stddev|46791.71589745555| 39198.86210105983|1.0607439611423475|\n",
      "|    min|                1|                 1|               0.5|\n",
      "|    25%|            40510|              1197|               3.0|\n",
      "|    50%|            80906|              2947|               3.5|\n",
      "|    75%|           121545|              8623|               4.0|\n",
      "|    max|           162541|            209171|               5.0|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    userCol =\"userId\",\n",
    "    itemCol =\"movieId\",\n",
    "    ratingCol = \"rating\",\n",
    ")\n",
    "(training_data, validation_data) = ratings.randomSplit([8.0,2.0])\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",labelCol=\"rating\",predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "model = als.fit(training_data)\n",
    "predictions = model.transform(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelRecNormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|31563 |107406 |3.5   |3.4534233 |\n",
      "|31563 |96966  |4.0   |4.1158876 |\n",
      "|31563 |103253 |3.0   |2.9561546 |\n",
      "|31563 |106452 |3.0   |3.9261878 |\n",
      "|31563 |96821  |2.0   |3.7020555 |\n",
      "|31563 |108727 |4.5   |3.698239  |\n",
      "|31563 |105246 |4.0   |3.5068374 |\n",
      "|31563 |104923 |3.5   |3.865512  |\n",
      "|31563 |107771 |4.0   |3.8892705 |\n",
      "|31563 |99145  |3.5   |3.3802044 |\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = evaluator.evaluate(predictions.na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Base Model*\n",
      "RMSE: 0.8068647889211222\n",
      " Rank: 10\n",
      " MaxIter: 10\n",
      " RegParam: 0.1\n"
     ]
    }
   ],
   "source": [
    "print (\"*Base Model*\")\n",
    "print (f\"RMSE: {rmse}\")\n",
    "print (f\" Rank: {model.rank}\")\n",
    "print (f\" MaxIter: {model._java_obj.parent().getMaxIter()}\")\n",
    "print (f\" RegParam: {model._java_obj.parent().getRegParam()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userFactors=model.userFactors\n",
    "# itemFactors = model.itemFactors\n",
    "# userFactors.sort('id').show(5,False)\n",
    "# itemFactors.sort('id').show(5,False)\n",
    "# import numpy as np\n",
    "# user91Features = model.userFactors.filter(f.col('id')==91).select(f.col('features')).rdd.flatMap(lambda x:x).collect()[0]\n",
    "# item471Features = model.itemFactors.filter(f.col('id')==471).select(f.col('features')).rdd.flatMap(lambda x:x).collect()[0]\n",
    "\n",
    "# print(user91Features)\n",
    "# print(item471Features)\n",
    "# print('Predicted rating of user 91 for movie 471: ' + str(np.dot(user91Features, item471Features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cần máy mạnh để train\n",
    "# param_grid = ParamGridBuilder()\\\n",
    "#     .addGrid(als.rank, [5, 40, 80, 120])\\\n",
    "#     .addGrid(als.maxIter, [5, 100, 250, 500])\\\n",
    "#     .addGrid(als.regParam, [0.05, 0.1, 1.5])\\\n",
    "#     .build()\n",
    "\n",
    "# Tell Spark what values to try for each hyperparameter\n",
    "param_grid = (ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [5, 10]) \\\n",
    "    .addGrid(als.maxIter, [20]) \\\n",
    "    .addGrid(als.regParam, [0.05,0.1]) \\\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Build cross validation step using CrossValidator\n",
    "cv = CrossValidator(estimator=als,\n",
    "                    estimatorParamMaps=param_grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cv on the training data\n",
    "model_cv = cv.fit(training_data)\n",
    "# Extract best combination of values from cross validation\n",
    "best_model = model_cv.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"modelRecBest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.transform(validation_data)\n",
    "rmse = evaluator.evaluate(predictions.na.drop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Best Model*\n",
      "RMSE: 0.8024075892997405\n",
      " Rank: 5\n",
      " MaxIter: 20\n",
      " RegParam: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics and model parameters\n",
    "print (\"*Best Model*\")\n",
    "print (f\"RMSE: {rmse}\")\n",
    "print (f\" Rank: {best_model.rank}\")\n",
    "print (f\" MaxIter: {best_model._java_obj.parent().getMaxIter()}\")\n",
    "print (f\" RegParam: {best_model._java_obj.parent().getRegParam()}\") "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db772567c4567f4b3d1f56ed53e5d7229d15382f6d3dfec57e0c55f7b5cf2dd9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
